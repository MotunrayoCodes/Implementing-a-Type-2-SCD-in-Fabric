# Implementing-a-Type-2-SCD-in-Fabric

 Overview
This project implements a Type 2 Slowly Changing Dimension logic to track historical employee data using PySpark within a Microsoft Fabric notebook.

ðŸ›  Hereâ€™s a quick breakdown of the workflow:

ðŸ”¹ Uploaded and converted the raw dataset to a Delta table
ðŸ”¹ Cleaned the data:
â€ƒâ€ƒâ€¢ Converted LoadDate column to proper Date type.
â€ƒâ€ƒâ€¢ Filled nulls in LoadDate with current date using coalesce()
â€ƒâ€ƒâ€¢ Removed duplicates.
ðŸ”¹ Created an empty dimension table to track historical employee data.
ðŸ”¹ Applied SCD2 logic using window functions:
â€ƒâ€ƒâ€¢ Set StartDate from LoadDate.
â€ƒâ€ƒâ€¢ Used lead() to compute EndDate.
â€ƒâ€ƒâ€¢ Marked current records with IsActive = Yes.
ðŸ”¹ Dropped temporary columns and saved final output to dim_employee with schema overwrite enabled.

<img width="849" height="463" alt="final_employee table" src="https://github.com/user-attachments/assets/e75e917f-1c3e-496b-8368-591128df0a73" />

